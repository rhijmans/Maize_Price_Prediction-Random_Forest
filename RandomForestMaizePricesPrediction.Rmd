---
title: "RandomForestMaizePricesPrediction"
#author: "Kevin Oluoch"
#date: "4/29/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
```

## Random Forest Prediction of Maize Prices

### Introduction
Maize price estimates covering a continuous geographical area are difficult to collect: It costs a lot and takes time to collect the data. Using a supervised classification model that associates the maize prices at known locations and spatial variables, one can predict the maize price in other locations with the same spatial variables. An ideal model should be simple enough to develop and use, yet complex enough to emulate all empherical and/or theoretical associations. 

Models based on the [random forest algorithm (developed by Leo Breiman)](https://link.springer.com/content/pdf/10.1023%2FA%3A1010933404324.pdf) attempt to achieve this ensemble. The random forest algorithm creates decision trees that classify the data into preditermined classes. The decision trees are created based on random subsets of the training data - input data. Each tree makes a classification of the data to create a set of responces; the final class is the mode of these responces.


In this exercise we use the "randomForest" library in R, which is based on a FORTRAN code developed by Leo Breiman and Adele Cutler. The exercise is divided into four methodical steps: (I) The Data, (II) Classification Model, (III) Price Prediction, (IV) Analysis.

### (I) The Data
There are two sets of data for this exersice: A csv(comma delimited file) with maize prices from diffrent locations in Tanzania; and several raster files of  weather elements, soil properties and distance to infrastructure/amenities that encompase Tanzania. 

We convert the maize price csv to a shapefile, and use it to extract data from the rasters. This extracted data -Training data - is used to create the random forest model as the predictors and the maize price from the csv as the responce. The Raster files are subsequently used to predict Maize prices in the whole of Tanzania.

#### 1. The Maize Prices data
##### a) Load Maize Price Data
Load the maize prices data into a dataframe(R object) using the "read.csv" function, which is a wrapper function for "read.table", customized for csv files.

```{r }
maize.price <- read.csv("./TZ_maize_prices_2015.csv")
```

We can view the first 6 rows of the data using the function "head"
```{r}
head(maize.price)
```



##### b) Create a Shapefile (spatialPointsDataframe)
In creating  a shapefile (spatialPointsDataframe), you have to specify the coordinate system on which the points are based.
We use the "sp", "raster" and "rgdal" R packages for creating and manipulating spatial data in this exercise. They are all add-on packages that have to be installed from CRAN.
```{r echo=FALSE}
library(raster) # Will load "sp" package as a dependency
library(rgdal)
```
The longitude and latitude values above are decimal degrees in the [WGS84](https://confluence.qps.nl/qinsy/en/world-geodetic-system-1984-wgs84-29855173.html) system. So first we create a WGS84 object of class "CRS" (coordinate reference system) that will be used to specify this system.


```{r}
# wgs84.prj: projection for coordinates in prices csv
wgs84.prj <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
```



We then use the object to create a shapefile with an attribute table containing the Coordinates and price data. we then plot the shapefile to see  distribution of the locations and ensure they all lie within the borders.
```{r}
maizeprice <- SpatialPointsDataFrame( coords = data.frame( maize.price$Longitude, maize.price$Latitude ), 
                                      data = maize.price,
                                      proj4string = wgs84.prj 
                                     )

TZA_natbnd <- getData('GADM', country='TZA', level=0)
plot(TZA_natbnd)
plot(maizeprice, axes = TRUE, pch = 20, col = "Red", add = TRUE)
```


##### c) Shapefile Projection Transformation
We convert the maize prices shapefile to the 
 [Lambert azimuthal equal-area projection](https://en.wikipedia.org/wiki/Lambert_azimuthal_equal-area_projection) to match the raster data projecton. So first we create a lambert azimuthal equal-area (laea) projection object of class  "CRS" (coordinate reference system) and use it to transform the coordinates to the laea projection.
```{r}
laea.prj <- CRS("+proj=laea +lat_0=5 +lon_0=20 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")

maizeprice_laea <- spTransform(maizeprice, laea.prj)
```


#### 2. Raster Data Set (weather elements, soil properties and distance to amenities)
##### a) Create raster stack
To create a raster stack of weather elements, soil properties and distance to infrastructure/amenities data, we succesively load each raster then add it to the stack. The raster files with data on  should be in a single directory in the working environment. 


Set up an empty stack to hold rasters and assign it the Lambert azimuthal equal-area projection, then add the rasters in the directors (named rasters in this exercise) to the stack in a "for" loop.
```{r}
rasterstack <- stack() 
crs(rasterstack) <- laea.prj # raster::crs differs with sp::CRS

rasterlist <- list.files(path = "./rasters", 
                         pattern = "*.tif$", 
                         full.names = TRUE) # Character vector of relative filepaths
for (rasterpath in rasterlist) {
      rasterfile <- raster(rasterpath)
      rasterstack <- addLayer(rasterstack, rasterfile)
    }
```

##### b) Add Latitude and Longitude Rasters
We add longitude and latitude rasters to the stack so our model considers location in its prediction. The longitude and latitude rasters will have their longitude position and latitude position respectively, as the cell values.
We use one raster from the stack as a reference to ensure the latitude and longitude rasters have the same properties.
```{r}
refrenceraster <- rasterstack[[1]]
```

we'll create the latitude and longitude rasters that are inline with the national boundary  in 4 steps: Transform the Tanzania shapefile -downloaded earlier- to the Lambert azimuthal equal-area projection; change it to a raster with the reference raster's properties, extract the latitude and longitude values from the created raster; assign the values to two copies of the created raster: longitudes to one, latitudes to the other.

```{r}
natbnd_laea <- spTransform(TZA_natbnd, laea.prj)

natbnd.raster <- rasterize(natbnd_laea, refrenceraster) # Takes time ~ 10 min

latitudes <- xFromCell(natbnd.raster, 1:length(natbnd.raster))  
longitudes <- yFromCell(natbnd.raster, 1:length(natbnd.raster))

natbnd.raster.lati <- natbnd.raster.long <- natbnd.raster
values(natbnd.raster.lati) <- latitudes
values(natbnd.raster.long) <- longitudes
```


Name the raster cell values and add them to the rasters stack.
```{r}
names(natbnd.raster.long) <- "Longitude"
names(natbnd.raster.lati) <- "Latitude"

rasterstack <- stack(rasterstack, natbnd.raster.long, natbnd.raster.lati)
```

We end up with a raster stack of all the prediction variables. 
```{r}
names(rasterstack)
```


#### 3. Create Training Data
The responce variable - maize prices - is point data. To create model training data, we extract point data from the prediction variables - raster stack. A pixel value may have been afected by random errors or may be an outlier case. To get a representational value for all the points, we extract the mean value in pixels in a 5000 meters radius (ground distance)
```{r}
# Takes Time ~ 20 min
extdata = extract(rasterstack, 
                  maizeprice_laea, 
                  buffer=5000, # Meters
                  small=TRUE, 
                  fun = mean) 
```


some points may skew the classification model if they fall in an area with missing data in any of the prediction rasters.To improve accuracy of the model, we'll remove price locations that have "NA" values in any column of the extracted data.
```{r}
extdata <- extdata[complete.cases(extdata),]
```

View the training data.
```{r}
head(extdata, 3)
```






### (II) Classification Model - Random Forest

The classification model is based on the random forest algorithm; which works by developing a model- with an optimal number of decision Trees - that will make known predictions from the training data. The decision at each tree split is made by considering a subset of the prediction variables. the
so first, We get the optimal number of decision trees for the training data - in a process called tunning the forest, then we'll specify that value when creating the model by running the "randomForest" function. 


We'll use functions from the "randomForest" library for model creation and price prediction stages.
```{r echo=FALSE}
library(randomForest)
```

#### Tune the forest
When running the random forest algorithm, we need to declare the optimal number of decision trees the algorithm should create. Too many Trees and the algorithm will over-fit the model and be to strict to make good predictions with new data; Too few Trees and the algorithm will under-fit the model and be unable to model the training data effectively. so first, we use "tuneRF" function from the "randomForest" library to get possible optimal number of trees. The "tuneRF" function requires two variables: the prediction variables and the responce variable. 


```{r}
trf <- tuneRF(x=extdata, # Prediction variables
              y=maizeprice_laea@data[, "MaizePrice_TZS.KG"] # Responce variable
              ) 
```

We then select the number of  variables to sample from the suggested optimal numbers by considering the [Out-of-Bag error.](https://en.wikipedia.org/wiki/Out-of-bag_error)
```{r}
(mintree <- trf[which.min(trf[,2]),1])
```


#### Fit the model
We can then fit a model with the optimal number of trees. (Take a lot of time (~1 hour): Exact time will depend on the computer's RAM processor speed and other running programs)
```{r}
maizerfmodel <- randomForest(x=maizepriceatt[, mypredictors],
                             y=maizepriceatt[, responce],
                             mtry=mintree,importance = TRUE
                             )
```

We can view the randomForest object
```{r}
maizerfmodel
```

plot it
```{r}
plot(maizerfmodel)
```

A see the prediction variables in descending order of importance
```{r}
importance(maizerfmodel)
```

or a dot-chart of variable importance
```{r}
varImpPlot(maizerfmodel)
```



### (III) Price Prediction
#### 8. Make predictions
The prediction can be done in two different ways: A spatial prediction and a non-spatial prediction

#### Spatial Prediction
made using the predict
```{r}
spatial.prediction <- raster::predict(rasterstack, maizerfmodel) # takes a long time!
```

plot prediction
```{r}
plot(spatial.prediction)
```


#### Spatial Prediction
made using the predict
```{r}
# non-spatial prediction and validation
non.spatial.prediction <- stats::predict(maizerfmodel, maizepriceatt[,mypredictors])
```
Evaluate the prediction
```{r}
library(caret)
round( RMSE( non.spatial.prediction,maizepriceatt[, responce] ) )
```

Plot the observed and predicted (non-spatial) values
```{r}
plot(
  maizepriceatt[, responce],
  non.spatial.prediction,
  col = 'blue',
  xlab = 'observed',
  ylab = 'predicted',
  xlim = c(00, 1600),
  ylim = c(00, 1600)
)
```


### (IV) Analysis
### 9. Assess the model
By the “pseudo R-squared”: 1 - mse / Var(y).
```{r}
pseudo.Rsq <- mean(maizerfmodel$rsq)
```

By the difference between the observed and the predicted values.
```{r}
prediction.diff <- maizepriceatt[,mypredictors] - maizerfmodel$predicted
head(prediction.diff)
```

